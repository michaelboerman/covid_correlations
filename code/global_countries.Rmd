---
title: "Covid Correlation with Population Density"
output:
  html_document:
    df_print: paged
  html_notebook: default
  word_document: default
---

Set up libraries and such:

```{r, message=FALSE, warning = FALSE}
library(readxl)
library(tidyverse)
library(lubridate)
library(countrycode)

# For data about deaths and cases
library(COVID19)

# For GGplot aestehtics
library(extrafont)
library(scales)
library(latex2exp)
library(ggpubr)

# need to load last, so doesn't get masked!
library(here)

# call the function file for plots
source(here::here("code/plot_cors.R"))
```

## Research Question: Does population density correlate with COVID-19 deaths or cases?

It seems logical that with a transmutable disease, such as the highly-infectious coronavrius, that a higher population density would facilitate higher cases or deaths. I'd like to explore this theory in the data.

First, I'll read in population densities for 264 countries. This data is static throughout 2020, such that the density for January 1st is the reported the same as December 31. This may not be true, but country-wide population count is not a particularly high-frequency time series, so I'm grateful we have any metric whatsoever.

```{r, message=FALSE, warning = FALSE}
# Read in densities
# Data comes from https://population.un.org/wpp/Download/Standard/Population/
density <- read_csv(here::here("data_input/pop_density.csv"),
  skip = 4
) %>%

  # drop everything except two columns, and rename while we're here
  transmute(
    country = `Country Name`,
    country_code = `Country Code`,
    density = `2018`
  ) %>%

  # if it doesn't have a density estimate, drop it.
  drop_na(density) %>%

  # Add in the numeric country code, for use late.
  mutate(country_code_num = countrycode(country_code,
    origin = "iso3c",
    destination = "iso3n",
    nomatch = NA
  )) %>%
  identity()

# in developement, I also read-in population counts. This is not needed in the
# final product, but I'll carry over the naming convention
country_pops <- density
```

Next, we need to load the covid data -- notably, the number of cases and deaths.

```{r}
# See this incredible package https://cran.r-project.org/web/packages/COVID19/index.html

# View(covid19cite(covid19()))
# get the case and death counts from JHU CSSE

covid_data <- COVID19::covid19(verbose = FALSE) %>%

  # rename to match what we have in country_pops dataframe
  dplyr::rename(country_code = id) %>%

  # and now join using this column
  left_join(country_pops, by = "country_code") %>%
  identity()
```

Now we can plot!
```{r}
# call the special function
plot_one_date(
  df = covid_data,
  date = "last",
  x_series = "density",
  y_series = "confirmed",
  title = "How do population density and COVID cases relate?",
  subtitle = paste0(
    "Using global-level data on ",
    format(Sys.Date() - 1, "%B %d, %Y")
  ),
  caption = "Data: JHU CSSE\n Calculation; Chart: Michael Boerman github.com/michaelboerman",
  filename = "global_one_date_cases"
)
```

Now, let's look at a pure pearson's correlation to see how these two move together.

```{r}
cor.test(covid_data$density, covid_data$deaths, method = "pearson")
cor.test(covid_data$density, covid_data$confirmed, method = "pearson")
```

Look at this! The correlation, in both cases, is most likely 0. We have a high degree of confidence they don't move together at all.

However, this is aggregated across *all* dates. Maybe the correlation *was* high, but with better lockdown measures or vaccine distribution, the correlation changes over time. And it's bad practice to take correlations across data that are independent. I don't have to run time series on each country to know there is serial correlation here.

Let's grab each correlation for a given date. In this dataframe, we have between 175 and 200 countries with complete data for any given date. This should be large enough to support a correlation test.

```{r}
# Grab the individual dates out of our long dataframe
unique_dates <- unique(covid_data$date)

# sort by date, such that Jan 2021 will come at the end, not beginning
# skip the last day, "today", because not all data will be in for all countries.
unique_dates <- unique_dates[order(unique_dates)] %>% head(length(unique_dates)-1)


# (I can't wait for R 4.1 native pipes... :) )

# initialize a DF to put in each date's correlation
cors_over_time <- data.frame(
  "date"      = unique_dates,
  "death_cor" = rep(NA, length(unique_dates)),
  "case_cor"  = rep(NA, length(unique_dates))
)

# for loop for calculating correlation per date
for (i in 1:length(unique_dates)) {

  # grab the data frame for that date i
  filtered_date_data <- covid_data %>%
    filter(date == unique_dates[i]) %>%
    identity()

  # insert correlation between pop density and deaths
  cors_over_time$death_cor[i] <- cor(filtered_date_data$density, filtered_date_data$deaths, use = "complete.obs")

  # insert correlation between pop density and confirmed cases
  cors_over_time$case_cor[i] <- cor(filtered_date_data$density, filtered_date_data$confirmed, use = "complete.obs")

  # insert the number of countries in the sampled date
  cors_over_time$n_countries_deaths[i] <-
    filtered_date_data %>%
    drop_na(deaths) %>%
    nrow()

  cors_over_time$n_countries_cases[i] <-
    filtered_date_data %>%
    drop_na(confirmed) %>%
    nrow()
}

# Early on in 2020, there are very few countries with deaths.
# A correlation on just a few data points is not much of a correlation at all, so I will filter these out.
# Cant do a simple filter, because deaths are NOT non-decreasing.
# I don't want gaps in a time series!

# Find the first time there are at least 20 countries:
cutoff <-
  cors_over_time %>%
  arrange(n_countries_cases) %>%
  filter(n_countries_cases >= 20) %>%
  head(n = 1) %>%
  pull(date) %>%
  ymd()

# and then re-assign only dates above this cutoff limit
cors_over_time <- cors_over_time %>% 
  filter(date > cutoff)
```

Now, let's plot!

```{r}
# Now let's do away with the icky for loop
#
# Cases:
plot_correlations(
  df = cors_over_time,
  x_series = "date",
  y_series = "case_cor",
  ylim <- 0.25,
  title = "Correlation between Population Density and COVID Cases across Countries",
  subtitle = "Each correlation shown is calculated using data just for that date, not cumulative.",
  caption = "Data: UN Population Dynamics; JHU CSSE. \n Calculations & Chart: Michael Boerman, https://github.com/michaelboerman",
  filename = "global_cor_density_cases"
)

# Deaths:
plot_correlations(
  df = cors_over_time,
  x_series = "date",
  y_series = "death_cor",
  ylim <- 0.25,
  title = "Correlation between Population Density and COVID Deaths across Countries",
  subtitle = "Each correlation shown is calculated using data just for that date, not cumulative.",
  caption = "Data: UN Population Dynamics; JHU CSSE. \n Calculations & Chart: Michael Boerman, https://github.com/michaelboerman",
  filename = "global_cor_density_deaths"
)
```

I'd like to plot the number of countries used for each correlation. This could be included on the above plots using a secondary axis (right side), but I don't want to make it too messy or convoluted. I can show the same info using the same axis and styling.

```{r}
plot_obs_used(
  data = cors_over_time,
  x_series = "date",
  y_series = "n_countries_cases",
  title = "Number of Countries or Regions used for Each Correlation",
  subtitle = paste0("Data starts on ", format(min(cors_over_time$date), "%B %d, %Y"), " which is the first day with cases in at least 20 regions"),
  caption = paste0("Data: JHU CSSE. \n Calculations & Chart: Michael Boerman, https://github.com/michaelboerman"),
  filename = "global_n_countries",
)
```
